{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "119da637-425b-4c5a-9c00-45fd1e2c50a4",
   "metadata": {},
   "source": [
    "## Streaming larger-than-memory datasets\n",
    "By the end of this lecture you will be able to:\n",
    "- process larger-than-memory datasets with streaming\n",
    "- identify which parts of a query run in the streaming engine\n",
    "- run a query on the GPU engine\n",
    "\n",
    "With the streaming engine Polars processes the query in multiple batches rather than all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7cab59-f01d-49f5-81c1-65c0ec6f0d92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe1e61a-71b9-471e-97ee-b8b4794d3e03",
   "metadata": {},
   "source": [
    "Obviously it doesn't work for me to provide very large datasets with this course. Instead we will do streaming on a small dataset and you can then apply it to your own larger datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959942c6-7050-487b-93bf-12e6c1bb1eb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_file = \"../data/nyc_trip_data_1k.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb3a6c9-7a84-4f04-9eb6-c3eb32d702a4",
   "metadata": {},
   "source": [
    "We start with a simple non-streaming query where we get the average of the float columns by number of passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1769b9-1530-4626-9f38-45117a09f615",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pl.scan_csv(csv_file,try_parse_dates = True)\n",
    "    .group_by(\"passenger_count\")\n",
    "    .agg(\n",
    "        pl.col(pl.Float64).mean()\n",
    "    )\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10010e89-017a-4d7e-8409-3e31ed1315ab",
   "metadata": {},
   "source": [
    "We ask Polars to process this query using the streaming engine by passing `engine=\"streaming\"` to `collect`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50432929-fc0c-4244-88af-014923c6bac5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pl.scan_csv(csv_file,try_parse_dates = True)\n",
    "    .group_by(\"passenger_count\")\n",
    "    .agg(\n",
    "        pl.col(pl.Float64).mean()\n",
    "    )    \n",
    "    .collect(engine=\"streaming\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dac011-d393-4977-9246-2cba05345cd3",
   "metadata": {},
   "source": [
    "With the streaming engine Polars processes the query in batches. At present only a subset of methods and expressions are supported by the streaming engine. If your full query is not supported by the streaming engine then Polars reverts back to the normal in-memory engine.\n",
    "\n",
    "In the old streaming engine you could check if a query would run in streaming mode because it would say `STREAMING` in the query plan like this:\n",
    "```\n",
    "STREAMING:\n",
    "  AGGREGATE\n",
    "    [col(\"trip_distance\").mean(), col(\"fare_amount\").mean(), col(\"tip_amount\").mean()] BY [col(\"passenger_count\")]\n",
    "    FROM\n",
    "    simple Ï€ 4/4 [\"trip_distance\", \"fare_amount\", ... 2 other columns]\n",
    "      Csv SCAN [../data/nyc_trip_data_1k.csv]\n",
    "      PROJECT 4/7 COLUMNS\n",
    "```\n",
    "\n",
    "However, this has not yet been implemented for the new streaming engine. The plan is to have something similar for the new engine so I leave the code below but commented out.\n",
    "\n",
    "<!-- You can use the `explain` method to see if a query will use the streaming engine by passing the `streaming=True` argument -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1b52a2-7e51-427e-baf3-d76cea77dfaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(\n",
    "#     pl.scan_csv(csv_file,try_parse_dates = True)\n",
    "#     .group_by(\"passenger_count\")\n",
    "#     .agg(\n",
    "#         pl.col(pl.Float64).mean()\n",
    "#     )\n",
    "#     .explain(streaming=True)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f250356-3e28-4535-b473-35b3f81bfb88",
   "metadata": {
    "tags": []
   },
   "source": [
    "The part of the query below `STREAMING` will be executed with the streaming engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ef26a7-a3ed-4e3d-b2e1-5d0f8ce31d9f",
   "metadata": {},
   "source": [
    "On the other hand only the first part of this query runs with the streaming engine as `rolling` is not a supported operation in the current streaming engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accf748e-3c0a-4361-8d38-f21dcf85fbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\n",
    "#     pl.scan_csv(csv_file,try_parse_dates = True)\n",
    "#     .sort(\"pickup\")\n",
    "#     .rolling(\n",
    "#         index_column=\"pickup\",\n",
    "#         period=\"1d\")\n",
    "#     .agg(\n",
    "#         pl.col(\"passenger_count\").mean()\n",
    "#     )\n",
    "#     .explain(streaming=True)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c38fb47-efef-4e75-9485-2f2dc63340e4",
   "metadata": {},
   "source": [
    "The good news is that many core methods work with the streaming engine including:\n",
    "- `select`\n",
    "- `with_columns`\n",
    "- `filter`\n",
    "- `join`\n",
    "- `group_by`\n",
    "\n",
    "<!-- However, the bad news is that even where the core method works in the streaming engine an expression that you use inside the method may not work in streaming and so that whole part of the query plan will not work in streaming.\n",
    "\n",
    "For example, here we call `shift` within `select`. As `shift` is not currently supported by the streaming engine the entire `select` does not work in the streaming engine -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63879b60-cf22-4b67-b5d5-5ab52043b26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\n",
    "#     pl.scan_csv(csv_file,try_parse_dates = True)\n",
    "#     .select(\n",
    "#         pl.col(\"pickup\").shift(1)\n",
    "#     )\n",
    "#     .explain(streaming=True)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeac017-bf87-4d52-a1d8-73766e5c2dd3",
   "metadata": {},
   "source": [
    "The reason for this is that streaming works in batches of rows. For the `shift` expression the last row in the batch needs data from another batch. This inter-batch communicaton is not currently supported and so streaming does not work for `shift`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cf39a4-fa92-4a32-b99f-9a2f869ca97c",
   "metadata": {},
   "source": [
    "### Tips for working with the streaming engine\n",
    "\n",
    "On help forums I have seen new users be frustrated with the streaming engine when they have developed a complex query which is not supported by the streaming engine and then find that they run out of memory. To avoid this I suggest following this process when processing larger-than-memory datasets:\n",
    "\n",
    "- start off with a simple query\n",
    "- check your query plan works in streaming mode with `explain`\n",
    "- add additional logic to the query plan\n",
    "- check your updated query plan works in streaming mode\n",
    "- continue adding logic and confirming that your query plan still works in streaming mode\n",
    "\n",
    "If you find that you have an operation that is not supported by streaming:\n",
    "- see if you can reduce the size of your dataset before the non-streaming part of the query plan e.g. by `filtering` the data or doing a `group_by` aggregation\n",
    "- replace non-streaming operations with streaming operations if possible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f70efd6-1dbd-4141-9537-70e15c228acd",
   "metadata": {},
   "source": [
    "### Profiling\n",
    "We can profile a query when we use streaming. Sadly this is currenrtly less useful than the non-streaming profile as the streaming part of the query plan is gathered together into a single block. Hopefully, this will be broken out in more detail in the revised streaming engine.\n",
    "\n",
    "> If you have not encountered `profile` see the lecture on Lazy Groupby in the section on Statistics, Counts and Grouping for an introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754084be-59a0-4412-be90-16d535ec43ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "groupDf, profileDF = (\n",
    "    pl.scan_csv(csv_file)\n",
    "    .group_by(\"passenger_count\")\n",
    "    .agg(\n",
    "        pl.col(\"trip_distance\").mean()\n",
    "    )\n",
    "    .sort(\"passenger_count\")\n",
    "    .profile(engine=\"streaming\",show_plot=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a04bc1-7327-4d13-ab96-c8e3a01ad92d",
   "metadata": {},
   "source": [
    "## GPU engine\n",
    "Polars has added support for partial processing of queries on an NVIDIA GPU. If you have an NVIDIA GPU available you can run a lazy query on the GPU engine by passing `engine=\"gpu\"` to `collect`. This is commented here as it raises an `Exception` if there is no GPU available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f55c18-d431-45c3-9c16-edcdcd88351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\n",
    "#     pl.scan_csv(csv_file,try_parse_dates = True)\n",
    "#     .select(\n",
    "#         pl.col(\"pickup\").shift(1)\n",
    "#     )\n",
    "#     .collect(engine=\"gpu\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557d47d6-51ab-44ea-a6cd-ec06e95534b3",
   "metadata": {},
   "source": [
    "The GPU engine is still in its early days and so only a subset of operations are supported. \n",
    "\n",
    "> Only NVIDIA GPUs are supported - in fact the GPU engine only happened because of support from NVIDIA. There are no plans for other GPUs to be supported."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
